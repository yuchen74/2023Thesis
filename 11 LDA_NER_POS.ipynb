{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "inclusive-fellowship",
   "metadata": {},
   "source": [
    "# XXX - topics & named-entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "suited-heart",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "from nltk import word_tokenize, corpus\n",
    "import gensim\n",
    "from gensim import corpora,models\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import pyLDAvis.gensim_models\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ranking-weapon",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\charliehebdo-df-2.csv', \\\n",
    "                 encoding = 'utf-8', header = 0)\n",
    "src_tw_df = pd.read_csv(r'D:\\論文\\PHEME9\\Data\\CSV\\charliehebdo-src-2.csv', \\\n",
    "                        encoding = 'utf-8', header =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "composed-probe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28978"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(src_tw_df.loc[src_tw_df.label==0])+len(df.loc[df.label==0]) #number of rumorous tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "later-meditation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "rumor_tw = df.cleaned_reply_tw[df.label ==0 ].append(src_tw_df.cleaned_src_tw[src_tw_df.label ==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "modified-chain",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "non_rumor_tw = df.cleaned_reply_tw[df.label ==1 ].append(src_tw_df.cleaned_src_tw[src_tw_df.label ==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "continental-macro",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "rumor_tw_list = rumor_tw.astype(str).apply(word_tokenize).tolist()\n",
    "non_rumor_tw_list = non_rumor_tw.astype(str).apply(word_tokenize).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-combining",
   "metadata": {},
   "source": [
    "## LDA model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-terror",
   "metadata": {},
   "source": [
    "### Rumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aggregate-connectivity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(23950 unique tokens: ['dead', 'shoot', 'today', 'consider', 'guess']...)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "#Rumor dictionary\n",
    "id2word = corpora.Dictionary(rumor_tw_list)\n",
    "print(id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "economic-maple",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Term Document Frequency\n",
    "corpus_r = [id2word.doc2bow(tw) for tw in rumor_tw_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(corpus, dictionary, k):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, \n",
    "                                         texts=rumor_tw_list, #要改\n",
    "                                         dictionary=id2word,    #要改\n",
    "                                         coherence='c_v')\n",
    "    return coherence_model_lda.get_coherence()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-majority",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topics range\n",
    "min_topics = 2\n",
    "max_topics = 11\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results ={'Topics': [], 'Coherence': []}\n",
    "\n",
    "for k in topics_range:\n",
    "\n",
    "    # get the coherence score for the given parameters\n",
    "    cv = compute_coherence_values(corpus=corpus_r, \n",
    "                                  dictionary=id2word,k=k)\n",
    "    # Save the model results\n",
    "    model_results['Topics'].append(k)\n",
    "    model_results['Coherence'].append(cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = pd.DataFrame(model_results)\n",
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show graph\n",
    "import matplotlib.pyplot as plt\n",
    "limit=11; start=2; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(model_results.Topics, model_results.Coherence)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-screening",
   "metadata": {},
   "source": [
    "Pick **k = 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_r = gensim.models.LdaMulticore(corpus=corpus_r,id2word=id2word,num_topics=4, \n",
    "                                       random_state=100,chunksize=100,passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "rumor_topics = pyLDAvis.gensim_models.prepare(lda_model_r,corpus_r,id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-cooperative",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.display(rumor_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-hindu",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_r = pyLDAvis.gensim_models.prepare(lda_model_r, corpus_r, id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-thickness",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'D:/論文/PHEME9/Code/graph/lda\\\\'\n",
    "pyLDAvis.save_html(p_r, save_path+'charliehebdo_lda_r.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Keyword in the 4 topics\n",
    "topic_term = pd.DataFrame()\n",
    "\n",
    "for topic in lda_model_r.print_topics(num_words = 30):\n",
    "    terms = [] \n",
    "#     print(topic[0],\":\")\n",
    "    listOfTerms = topic[1].split('+')\n",
    "    for term in listOfTerms:\n",
    "        listItems = term.split('*')\n",
    "        terms.append(listItems[1])\n",
    "    topic_term.insert(topic[0],\"#\"+str(topic[0]) ,terms)\n",
    "topic_term\n",
    "\n",
    "topic_term.to_csv('D:/論文/PHEME9/Code/charliehebdo/LDA_terms_r_charliehebdo.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-pressing",
   "metadata": {},
   "source": [
    "### Non-rumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word_nr = corpora.Dictionary(non_rumor_tw_list)\n",
    "corpus_nr = [id2word_nr.doc2bow(tw) for tw in non_rumor_tw_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(corpus, dictionary, k):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, \n",
    "                                         texts=non_rumor_tw_list, #要改\n",
    "                                         dictionary=id2word_nr,    #要改\n",
    "                                         coherence='c_v')\n",
    "    return coherence_model_lda.get_coherence()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results_nr ={'Topics': [], 'Coherence': []}\n",
    "\n",
    "for k in topics_range:\n",
    "\n",
    "    # get the coherence score for the given parameters\n",
    "    cv = compute_coherence_values(corpus=corpus_nr, \n",
    "                                  dictionary=id2word_nr,k=k)\n",
    "    # Save the model results\n",
    "    model_results_nr['Topics'].append(k)\n",
    "    model_results_nr['Coherence'].append(cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results_nr = pd.DataFrame(model_results_nr)\n",
    "model_results_nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show graph\n",
    "import matplotlib.pyplot as plt\n",
    "limit=11; start=2; step=1;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(model_results_nr.Topics, model_results_nr.Coherence)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-kernel",
   "metadata": {},
   "source": [
    "Pick **k = 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-brazil",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_nr = gensim.models.LdaMulticore(corpus=corpus_nr,id2word=id2word_nr,num_topics=3, \n",
    "                                       random_state=100,passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_rumor_topics = pyLDAvis.gensim_models.prepare(lda_model_nr,corpus_nr,id2word_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.display(non_rumor_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(lda_model_nr.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_nr = pyLDAvis.gensim_models.prepare(lda_model_nr, corpus_nr, id2word_nr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'D:/論文/PHEME9/Code/graph/lda\\\\'\n",
    "pyLDAvis.save_html(p_nr, save_path+'charliehebdo_lda_nr.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Keyword in the 4 topics\n",
    "topic_term_nr = pd.DataFrame()\n",
    "\n",
    "for topic in lda_model_nr.print_topics(num_words = 30):\n",
    "    terms = [] \n",
    "#     print(topic[0],\":\")\n",
    "    listOfTerms = topic[1].split('+')\n",
    "    for term in listOfTerms:\n",
    "        listItems = term.split('*')\n",
    "        terms.append(listItems[1])\n",
    "    topic_term_nr.insert(topic[0],\"#\"+str(topic[0]) ,terms)\n",
    "topic_term_nr\n",
    "\n",
    "topic_term_nr.to_csv('D:/論文/PHEME9/Code/charliehebdo/LDA_terms_nr_charliehebdo.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-nitrogen",
   "metadata": {},
   "source": [
    "## BERTopic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "charming-latest",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pip 22.2.2 from c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip (python 3.9)\n",
      "Collecting bertopic==0.3.1\n",
      "  Using cached bertopic-0.3.1-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from bertopic==0.3.1) (4.62.3)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command python setup.py egg_info\n",
      "ERROR: No .egg-info directory found in C:\\Users\\user\\AppData\\Local\\Temp\\pip-pip-egg-info-zoqy1ojb\n"
     ]
    }
   ],
   "source": [
    "!pip install -v bertopic==0.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "# topic_model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True)\n",
    "# topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-seminar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "previous-hamilton",
   "metadata": {},
   "source": [
    "## Clustering Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "danish-thriller",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering, KMeans, MiniBatchKMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-blend",
   "metadata": {},
   "source": [
    "### Rumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "reasonable-maryland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28978, 69)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.7,min_df=0.01,stop_words=\"english\")\n",
    "X = vectorizer.fit_transform(rumor_tw.astype(str).tolist())\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-clearing",
   "metadata": {},
   "source": [
    "#### Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-butter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_clusters(data, max_k):\n",
    "    iters = range(2, max_k+1, 1)\n",
    "    \n",
    "    sse = []\n",
    "    for k in iters:\n",
    "        sse.append(KMeans(n_clusters=k, random_state=100).fit(data).inertia_)\n",
    "       \n",
    "    f, ax = plt.subplots(1, 1)\n",
    "    ax.plot(iters, sse, marker='o')\n",
    "    ax.set_xlabel('Cluster Centers')\n",
    "    ax.set_xticks(iters)\n",
    "    ax.set_xticklabels(iters)\n",
    "    ax.set_ylabel('SSE')\n",
    "    ax.set_title('SSE by Cluster Center Plot')\n",
    "    \n",
    "find_optimal_clusters(X, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "molecular-sector",
   "metadata": {},
   "source": [
    "Pick **no. of cluster = 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = KMeans(n_clusters=4, random_state=100).fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X.todense()).groupby(clusters).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_keywords(data, clusters, labels, n_terms):\n",
    "    df = pd.DataFrame(data.todense()).groupby(clusters).mean()\n",
    "    cluster_term = pd.DataFrame()\n",
    "    \n",
    "    for i,r in df.iterrows():\n",
    "        terms = []\n",
    "        for t in np.argsort(r)[-n_terms:]:\n",
    "            terms.append(labels[t] )\n",
    "        cluster_term.insert(i,str(i),terms)\n",
    "    \n",
    "    return cluster_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_r = get_top_keywords(X, clusters, vectorizer.get_feature_names(), 20)\n",
    "kmeans_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_r.to_csv('D:/論文/PHEME9/Code/charliehebdo/kmeans_terms_r_charliehebdo.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-cancer",
   "metadata": {},
   "source": [
    "#### Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "graphic-miniature",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, ward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acute-progressive",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AgglomerativeClustering(distance_threshold=0.2, n_clusters=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AgglomerativeClustering</label><div class=\"sk-toggleable__content\"><pre>AgglomerativeClustering(distance_threshold=0.2, n_clusters=None)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AgglomerativeClustering(distance_threshold=0.2, n_clusters=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AgglomerativeClustering(n_clusters=None, distance_threshold = 0.2)\n",
    "model.fit(X.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "opposed-rally",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\ipykernel\\ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 257, 4919,  817, ..., 2136,  743,  854], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = 1 - cosine_similarity(X)\n",
    "linkage_matrix = ward(dist) #define the linkage_matrix using ward clustering pre-computed distances\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "dn = dendrogram(linkage_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-mixture",
   "metadata": {},
   "source": [
    "### Non-Rumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-marble",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.7,min_df=0.01,stop_words=\"english\")\n",
    "Y = vectorizer.fit_transform(non_rumor_tw.astype(str).tolist())\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-disease",
   "metadata": {},
   "source": [
    "#### Kmeans "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_optimal_clusters(Y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-gibson",
   "metadata": {},
   "source": [
    "Pick **no. of cluster = 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = KMeans(n_clusters=3, random_state=100).fit_predict(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_nr = get_top_keywords(Y, clusters, vectorizer.get_feature_names(), 20)\n",
    "kmeans_nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_nr.to_csv('D:/論文/PHEME9/Code/charliehebdo/kmeans_terms_nr_charliehebdo.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-taste",
   "metadata": {},
   "source": [
    "#### Hierachical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-cigarette",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nr = AgglomerativeClustering(compute_distances = True,n_clusters=3)\n",
    "model_nr.fit(Y.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intellectual-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nr.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-debate",
   "metadata": {},
   "source": [
    "## Named entity recognition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-tanzania",
   "metadata": {},
   "source": [
    "### Rumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = rumor_tw.astype('str').apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = []\n",
    "label = []\n",
    "tw_ent = []\n",
    "\n",
    "for i in range(len(a)):\n",
    "    each_tw_ents = a.iloc[i].ents\n",
    "    \n",
    "    for ent in each_tw_ents:\n",
    "        entity.append(ent.text)\n",
    "        label.append(ent.label_)\n",
    "    \n",
    "    tw_ent.append(list(each_tw_ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-angel",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = pd.DataFrame({'Entity': entity, 'label':label})\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "top50_ent_r = entities.Entity.value_counts()[:50,].to_frame().reset_index()\n",
    "top50_ent_r.columns=['Entity','Count']\n",
    "top50_ent_r['Percentage'] = top50_ent_r['Count'] / sum(top50_ent_r.Count)\n",
    "top50_ent_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "top50_ent_r.to_csv('D:/論文/PHEME9/Code/charliehebdo/top50_ent_r.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-representative",
   "metadata": {},
   "source": [
    "### Non-rumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-found",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = non_rumor_tw.astype('str').apply(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_nr = []\n",
    "label_nr = []\n",
    "nr_tw_ent = []\n",
    "\n",
    "for i in range(len(b)):\n",
    "    each_tw_ents = b.iloc[i].ents\n",
    "    \n",
    "    for ent in each_tw_ents:\n",
    "        entity_nr.append(ent.text)\n",
    "        label_nr.append(ent.label_)\n",
    "    \n",
    "    nr_tw_ent.append(list(each_tw_ents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_nr = pd.DataFrame({'Entity': entity_nr, 'label':label_nr})\n",
    "entities_nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-value",
   "metadata": {},
   "outputs": [],
   "source": [
    "top50_ent_nr = entities_nr.Entity.value_counts()[:50,].to_frame().reset_index()\n",
    "top50_ent_nr.columns=['Entity','Count']\n",
    "top50_ent_nr['Percentage'] = top50_ent_nr['Count'] / sum(top50_ent_nr.Count)\n",
    "top50_ent_nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documentary-campaign",
   "metadata": {},
   "outputs": [],
   "source": [
    "top50_ent_nr.to_csv('D:/論文/PHEME9/Code/charliehebdo/top50_ent_nr.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-snapshot",
   "metadata": {},
   "source": [
    "## POS Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-conditions",
   "metadata": {},
   "source": [
    "### Rumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-charlotte",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_r = []\n",
    "\n",
    "for i in range(len(a)):\n",
    "    for token in a.iloc[i]:\n",
    "        tagging_r.append(token.tag_)\n",
    "# tagging_r     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "tag_set_r = Counter(tagging_r)\n",
    "tag_r = pd.DataFrame.from_dict(tag_set_r, orient='index').reset_index()\n",
    "tag_r.columns=['tag','count']\n",
    "tag_r.sort_values(by='count',inplace=True,ascending=False)\n",
    "tag_r.reset_index(drop=True, inplace=True)\n",
    "tag_r\n",
    "tag_r.to_csv('D:/論文/PHEME9/Code/charliehebdo/tagging_r.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-induction",
   "metadata": {},
   "source": [
    "### Non-rumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-longer",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging_nr = []\n",
    "pos_nr = []\n",
    "\n",
    "for i in range(len(b)):\n",
    "    for token in b.iloc[i]:\n",
    "        tagging_nr.append(token.tag_)\n",
    "\n",
    "# tagging_nr    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_set_nr = Counter(tagging_nr)\n",
    "tag_nr = pd.DataFrame.from_dict(tag_set_nr, orient='index').reset_index()\n",
    "tag_nr.columns=['tag','count']\n",
    "tag_nr.sort_values(by='count',inplace=True,ascending=False)\n",
    "tag_nr.reset_index(drop=True, inplace=True)\n",
    "tag_nr\n",
    "tag_nr.to_csv('D:/論文/PHEME9/Code/charliehebdo/tagging_nr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-taste",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_nr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-championship",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
